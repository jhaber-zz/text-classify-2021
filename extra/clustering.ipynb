{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsuperivsed ML method used to group data points based on their features alone, and no observed grouping labels as in supervised classification. Thus most clustering alorithms seeks to group points by their distance in a high dimensional space generated by provided features.\n",
    "\n",
    "Below is a plot showing the results of the clustering algorithms in Scikit-Learn for several different toy datasets.\n",
    "\n",
    "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) K-means clustering  \n",
    "\n",
    "In this section we will cover k-means clustering using `scikit-learn`. The scikit-learn documentation for clustering is found [here](http://scikit-learn.org/stable/modules/clustering.html).\n",
    "\n",
    "First we'll import `KMeans` and `numpy` so that we can make our arrays. The `%matplotlib inline` will make our plots show up within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off with a few points. Remember, as with classification and regression, our data should be in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,1], [1,2], [1, 0], [-1, -3],\n",
    "             [15, 21], [18, 30], [20, 20], [22, 19],\n",
    "             [45, 50], [42, 48], [60, 40], [50, 50]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot them we can see that they appear to be arranged roughly in three groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X.T)\n",
    "plt.title('random points')\n",
    "plt.xlabel('feature0')\n",
    "plt.ylabel('feature1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get our clusters, all we have to do is specify how many we want, and then fit the model to the data. We'll choose 3. We can also specify the maximum number of iterations of the k-means algorithm, which you may want to do with a much larger dataset.\n",
    "\n",
    "First thing's first: **set a random seed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the model. Notice how we are chaining the 'fit' function onto the model instantiation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,\n",
    "               max_iter=300 #default\n",
    "               ).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the centers of the clusters through the `cluster_centers_` attribute. To get the labels (i.e. the corresponding cluster) we use `labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Centers\")\n",
    "print(kmeans.cluster_centers_)\n",
    "print()\n",
    "\n",
    "print(\"Labels\")\n",
    "print(kmeans.labels_)\n",
    "print()\n",
    "\n",
    "for point, label in zip(X, kmeans.labels_):\n",
    "    print(\"Coordinates:\", point, \"Label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's also plot out cluster centers along with the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(*X[kmeans.labels_==0,:].T, s=50, c='r', label='Cluster 0')\n",
    "ax1.scatter(*X[kmeans.labels_==1,:].T, s=50, c='b', label='Cluster 1')\n",
    "ax1.scatter(*X[kmeans.labels_==2,:].T, s=50, c='g', label='Cluster 2')\n",
    "ax1.scatter(*kmeans.cluster_centers_.T, s=50, marker='+', c='black', label='cluster centers')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('feature0')\n",
    "plt.ylabel('feature1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see to which cluster a new point would belong, we simply use the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.asarray([[0, 4],\n",
    "                        [19, 25],\n",
    "                        [40, 50]])\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print()\n",
    "\n",
    "print(\"0, 4\")\n",
    "print(\"Cluster:\", kmeans.predict([[0, 4]]))\n",
    "print()\n",
    "\n",
    "print(\"19, 25\")\n",
    "print(\"Cluster:\", kmeans.predict([[19, 25]]))\n",
    "print()\n",
    "\n",
    "print(\"40, 50\")\n",
    "print(\"Cluster:\", kmeans.predict([[40, 50]]))\n",
    "\n",
    "#plot new points\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(*X[kmeans.labels_==0,:].T, s=50, c='r', label='Cluster 0')\n",
    "ax1.scatter(*X[kmeans.labels_==1,:].T, s=50, c='b', label='Cluster 1')\n",
    "ax1.scatter(*X[kmeans.labels_==2,:].T, s=50, c='g', label='Cluster 2')\n",
    "ax1.scatter(*kmeans.cluster_centers_.T, s=50, c='black', marker='+', label='cluster centers')\n",
    "ax1.scatter(*new_points.T, s=50, c='cyan', label='new points')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('feature0')\n",
    "plt.ylabel('feature1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll show an example of agglomerative clustering, which is a type of hierarchical clustering. The documentation is [here](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering) in case you want to know more about the parameters. We'll use some of scikitlearn's toy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "n_samples = 1500\n",
    "\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)[0]\n",
    "blobs, blob_truth = datasets.make_blobs(n_samples=n_samples, random_state=0)\n",
    "\n",
    "plt.scatter(*noisy_moons.T)\n",
    "plt.ylabel('noisy moons')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(*blobs.T)\n",
    "plt.ylabel('blobs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use two clusters this time, and use ward linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "ward = AgglomerativeClustering(n_clusters=3,\n",
    "                               linkage='ward', #linkage can be ward (default), complete, or average\n",
    "                               affinity='euclidean') #affinity must be euclidean if linkage=ward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit the clustering model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward.fit(noisy_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll sort the points by label and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = np.array([point for label, point in zip(ward.labels_, noisy_moons) if label == 0])\n",
    "one = np.array([point for label, point in zip(ward.labels_, noisy_moons) if label == 1])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(*zero.T, s=50, c='b', label='zero')\n",
    "ax1.scatter(*one.T, s=50, c='r', label='one')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do the same with the blobs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward.fit(blobs)\n",
    "\n",
    "zero = np.array([point for label, point in zip(ward.labels_, blobs) if label == 0])\n",
    "one = np.array([point for label, point in zip(ward.labels_, blobs) if label == 1])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(*zero.T, s=50, c='b', label='zero')\n",
    "ax1.scatter(*one.T, s=50, c='r', label='one')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: DBSCAN \n",
    "\n",
    "\n",
    "It looks like our agglomerative clustering model did not cluster the noisy moons dataset how we might have wanted. For the challenge, use [`DBSCAN`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) to cluster noisy moons. Then plot the results and see what it looks like. Try an `eps` value of .2. This sets the maximum distance between two samples for them to be considered in the same neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model object\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# define model object\n",
    "dbscan = DBSCAN(eps=.2)\n",
    "\n",
    "# fit model to data \n",
    "dbscan.fit(noisy_moons);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fitted labels for each data point \n",
    "labels = dbscan.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(labels)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there any outliers not included in either cluster (indicated with a `-1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get inferred clusters\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into those for each cluster \n",
    "zero = np.array([point for label, point in zip(dbscan.labels_, noisy_moons) if label == 0])\n",
    "one = np.array([point for label, point in zip(dbscan.labels_, noisy_moons) if label == 1])\n",
    "\n",
    "# plot data with cluster assignment as the color \n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(*zero.T, s=50, c='b', label='zero')\n",
    "ax1.scatter(*one.T, s=50, c='r', label='one')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit another DBSCAN model to the blobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model object\n",
    "dbscan = DBSCAN(eps=0.2)\n",
    "\n",
    "# fit model to data \n",
    "dbscan.fit(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dbscan.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, see if there are outliers not included in any cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get inferred clusters\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot the points in the blobs dataset, coloring them by their cluster id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(blobs[:,0],blobs[:,1], s=50, c=labels, label='zero')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
