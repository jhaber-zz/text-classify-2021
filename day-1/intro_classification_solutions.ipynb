{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Supervised Machine Learning\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "* [Introduction](#intro)\n",
    "    * [Text classification in action](#example)\n",
    "    * [Text classification basics](#basics)\n",
    "* [Data preparation](#prepare)\n",
    "    * [Import modules](#import)\n",
    "    * [Read and preprocess data](#preprocess)\n",
    "    * [Divide data into training and test sets](#split)\n",
    "    * [Vectorize texts](#vectorize)\n",
    "* [Classification with supervised machine learning](#supervised)\n",
    "    * [Train logistic classifier model](#model)\n",
    "    * [Prediction on new data](#prediction)\n",
    "    * [Identify features](#features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation<a id='preparation'></a>\n",
    "\n",
    "## Import modules<a id='import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#scikit-learn is a huge library. We import what we need.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split #shortcut for dividing into train and test data\n",
    "from sklearn.metrics import confusion_matrix #shows confusion matrix--false/true positives/negatives\n",
    "from sklearn.metrics import accuracy_score #to asses the accuracy of the algorithm\n",
    "from sklearn.model_selection import cross_val_score #to compute cross validation for assessment purposes\n",
    "from sklearn.svm import LinearSVC #Linear Support Vector Classifier\n",
    "from sklearn.linear_model import LogisticRegression #Logistic regression classifier\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess data<a id='preprocess'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read our texts and turn them into lists\n",
    "review_path = 'poems/reviewed/'\n",
    "random_path = 'poems/random/'\n",
    "review_files = os.listdir(review_path)\n",
    "random_files = os.listdir(random_path)\n",
    "\n",
    "review_texts = [open(review_path+file_name, encoding='utf-8').read() for file_name in review_files]\n",
    "random_texts = [open(random_path+file_name, encoding='utf-8').read() for file_name in random_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body   label\n",
       "0  the the the the the the the the the the the th...  review\n",
       "1  the the the the the the the the the the the th...  review\n",
       "2  the the the the the the the the the the the th...  review"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform and concat these lists into a Pandas dataframe\n",
    "df1 = pd.DataFrame(review_texts, columns = ['body'])\n",
    "df1['label'] = \"review\"\n",
    "df2 = pd.DataFrame(random_texts, columns = ['body'])\n",
    "df2['label'] = \"random\"\n",
    "df = pd.concat([df1,df2])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Output some summary statistics for this dataframe. \n",
    "- How many poems have the review label, and how many bear the random label? \n",
    "- What is the total number of words in each category? \n",
    "- What is the average number of words per poem in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of poems in each category:\n",
      " review    360\n",
      "random    360\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "Token totals in each category: label\n",
      "random    7069809\n",
      "review    8260352\n",
      "Name: tokens, dtype: int64 \n",
      "\n",
      "Token averages in each category: label\n",
      "random    19638.358333\n",
      "review    22945.422222\n",
      "Name: tokens, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# solutions\n",
    "print('Total number of poems in each category:\\n', df['label'].value_counts(), '\\n')\n",
    "df['tokens'] = df['body'].str.split()\n",
    "df['tokens'] = df['tokens'].str.len()\n",
    "\n",
    "grouped = df.groupby('label')\n",
    "print('Token totals in each category:', grouped['tokens'].sum(), '\\n')\n",
    "print('Token averages in each category:', grouped['tokens'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['label'], order=df['label'].value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into training and test sets<a id='split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize our rows\n",
    "df = df.sample(720, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random    254\n",
       "review    246\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create two new dataframes\n",
    "df_train = df[:500]\n",
    "df_test = df[500:]\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize texts<a id='vectorize'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    114\n",
       "random    106\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the 'body' column into a document term matrix\n",
    "countvec = CountVectorizer(stop_words = 'english', min_df = 1, binary=True)\n",
    "\n",
    "training_dtm_tf = countvec.fit_transform(df_train.body)\n",
    "test_dtm_tf = countvec.transform(df_test.body)\n",
    "\n",
    "#create an array for labels\n",
    "training_labels = df_train.label\n",
    "test_labels = df_test.label\n",
    "test_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with supervised machine learning<a id='supervised'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic classifier model<a id='model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a container for our chosen algorithm, in this case logistic regression\n",
    "#one object contains all the functions for fitting data, making predictions, and storing parameters\n",
    "logit = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#fit a model on our training set\n",
    "logit.fit(training_dtm_tf, training_labels)\n",
    "\n",
    "#predict the labels on the test set using the trained model\n",
    "predictions_logit = logit.predict(test_dtm_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681818181818182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions_logit, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Text vectorization methods affect downstream classification accuracy. Above, we used simple term counts to turn texts into numbers. This time, instead of using term frequencies, use `sklearn`'s `TfidfVectorizer()` function to weight features with term frequency inverse document frequency (TF-IDF): this gives a word greater weight both when it is more frequent in a text AND when it is rare across the corpus. Does this vectorization approach improve classification accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "tfidfvec = TfidfVectorizer(stop_words = 'english', min_df = 1, binary=True)\n",
    "training_dtm_tfidf = tfidfvec.fit_transform(df_train.body)\n",
    "test_dtm_tfidf = tfidfvec.transform(df_test.body)\n",
    "\n",
    "logit = LogisticRegression(solver='liblinear')\n",
    "logit.fit(training_dtm_tfidf, training_labels)\n",
    "predictions_tfidf = logit.predict(test_dtm_tfidf) \n",
    "accuracy_score(predictions_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, TF-IDF seems to make our logistic regression classifier less accurate. So let's stick with term frequencies as our text vectorization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "A common practice in machine learning is to quickly try a bunch of algorithms, see which one works the best, and optimize it. In this spirit...\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Apply these two additional algorithms without bothering to learn how they work: \n",
    "- Linear Support Vector Classification (`LinearSVC()`) and \n",
    "- Multinomial Naive Bayes (`MultinomialNB()`)\n",
    "    \n",
    "To avoid a long delay, with `LinearSVC()` set `max_iter` to 30. \n",
    "\n",
    "Train each of these on the training set and evaluate accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7636363636363637"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "svc = LinearSVC(max_iter=30) #dual = False, loss='hinge'\n",
    "svc.fit(training_dtm_tf, training_labels)\n",
    "predictions_svc = svc.predict(test_dtm_tf) \n",
    "accuracy_score(predictions_svc, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(training_dtm_tf, training_labels)\n",
    "predictions_nb = nb.predict(test_dtm_tf) \n",
    "accuracy_score(predictions_nb, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**\n",
    "\n",
    "Try to improve the accuracy of either of these models by changing a few model parameters or the vectorizer function. (Decreases in accuracy are also informative.) This is basically a brute-force method of model optimization, which we'll learn more about tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7681818181818182"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "svc = LinearSVC(max_iter=100, dual = False) #loss='hinge'\n",
    "svc.fit(training_dtm_tf, training_labels)\n",
    "predictions_svc = svc.predict(test_dtm_tf) \n",
    "accuracy_score(predictions_svc, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on new data<a id='prediction'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickinson_canonic = \"\"\"Because I could not stop for Death – \n",
    "He kindly stopped for me –  \n",
    "The Carriage held but just Ourselves –  \n",
    "And Immortality.\n",
    "\n",
    "We slowly drove – He knew no haste\n",
    "And I had put away\n",
    "My labor and my leisure too,\n",
    "For His Civility – \n",
    "\n",
    "We passed the School, where Children strove\n",
    "At Recess – in the Ring –  \n",
    "We passed the Fields of Gazing Grain –  \n",
    "We passed the Setting Sun – \n",
    "\n",
    "Or rather – He passed us – \n",
    "The Dews drew quivering and chill – \n",
    "For only Gossamer, my Gown – \n",
    "My Tippet – only Tulle – \n",
    "\n",
    "We paused before a House that seemed\n",
    "A Swelling of the Ground – \n",
    "The Roof was scarcely visible – \n",
    "The Cornice – in the Ground – \n",
    "\n",
    "Since then – ‘tis Centuries – and yet\n",
    "Feels shorter than the Day\n",
    "I first surmised the Horses’ Heads \n",
    "Were toward Eternity – \"\"\"\n",
    "\n",
    "\n",
    "anthem_patriotic = \"\"\"O! say can you see, by the dawn's early light,\n",
    "What so proudly we hailed at the twilight's last gleaming,\n",
    "Whose broad stripes and bright stars through the perilous fight,\n",
    "O'er the ramparts we watched, were so gallantly streaming?\n",
    "And the rockets' red glare, the bombs bursting in air,\n",
    "Gave proof through the night that our flag was still there;\n",
    "O! say does that star-spangled banner yet wave\n",
    "O'er the land of the free and the home of the brave?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform these into DTMs with the same feature-columns as previously\n",
    "unknown_dtm = countvec.transform([dickinson_canonic,anthem_patriotic]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['review', 'random'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return binary classification\n",
    "logit.predict(unknown_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36267018, 0.63732982],\n",
       "       [0.68004536, 0.31995464]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return probability of classification. \n",
    "# Bayes theorem assigns a probability of membership in either category.\n",
    "# Just how confident is our classifier of its predictions?\n",
    "\n",
    "logit.predict_proba(unknown_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dickinson', 'review', array([0.36267018, 0.63732982])),\n",
       " ('anthem', 'random', array([0.68004536, 0.31995464]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's zip this together with the name of the poems to make sense of the output\n",
    "list(zip(['dickinson', 'anthem'], logit.predict(unknown_dtm), logit.predict_proba(unknown_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Import and process the 'canonic' (albeit unreviewed) volumes of poetry. Use the poetry classifier to predict whether they might have been reviewed.\n",
    "\n",
    "What do you think of the output? Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['256 Hopkins, Gerard Manley Poems of Gerard Manley Hopkins 1889.txt', '486 Dickinson, Emily Poems 1866.txt', '12 Lawrence, D. H. Look! We Have Come Through 1918.txt', '177 Hardy, Thomas Wessex Poems 1898.txt', '0 Lawrence, D. H. Tortoises 1921.txt', '169 Dunbar, Paul Laurence Lyrics of the Hearthside 1899.txt', '593 Brontë, Emily Poems of Acton, Currer, and Ellis Bell 1848.txt', '427 Harper, Frances Ellen Watkins Poems 1871.txt']\n"
     ]
    }
   ],
   "source": [
    "# solutions\n",
    "canonic_path = 'poems/canonic/'\n",
    "canonic_files = os.listdir(canonic_path)\n",
    "print(canonic_files)\n",
    "\n",
    "canonic_texts = [open(canonic_path+file_name, encoding='utf-8').read() for file_name in canonic_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['review', 'review', 'review', 'review', 'review', 'review',\n",
       "       'review', 'random'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonic_dtm = countvec.transform(canonic_texts).toarray()\n",
    "logit.predict(canonic_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.58073567e-07, 9.99999842e-01],\n",
       "       [6.60301436e-09, 9.99999993e-01],\n",
       "       [8.50025617e-09, 9.99999991e-01],\n",
       "       [8.36566983e-01, 1.63433017e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict_proba(canonic_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('256 Hopkins, Gerard Manley Poems of Gerard Manley Hopkins 1889.txt',\n",
       "  'review',\n",
       "  array([0., 1.])),\n",
       " ('486 Dickinson, Emily Poems 1866.txt', 'review', array([0., 1.])),\n",
       " ('12 Lawrence, D. H. Look! We Have Come Through 1918.txt',\n",
       "  'review',\n",
       "  array([0., 1.])),\n",
       " ('177 Hardy, Thomas Wessex Poems 1898.txt', 'review', array([0., 1.])),\n",
       " ('0 Lawrence, D. H. Tortoises 1921.txt',\n",
       "  'review',\n",
       "  array([1.58073567e-07, 9.99999842e-01])),\n",
       " ('169 Dunbar, Paul Laurence Lyrics of the Hearthside 1899.txt',\n",
       "  'review',\n",
       "  array([6.60301436e-09, 9.99999993e-01])),\n",
       " ('593 Brontë, Emily Poems of Acton, Currer, and Ellis Bell 1848.txt',\n",
       "  'review',\n",
       "  array([8.50025617e-09, 9.99999991e-01])),\n",
       " ('427 Harper, Frances Ellen Watkins Poems 1871.txt',\n",
       "  'random',\n",
       "  array([0.83656698, 0.16343302]))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(canonic_files, logit.predict(canonic_dtm), logit.predict_proba(canonic_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify features<a id='features'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() # naive bayes works best for this math\n",
    "nb.fit(training_dtm_tf, training_labels) # fit model\n",
    "\n",
    "def most_informative_features(text_class, vectorizer = countvec, classifier = nb, top_n = 20):\n",
    "    \"\"\"Returns feature name and odds ratio for a given class\"\"\"\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    class_index = np.where(classifier.classes_==(text_class))[0][0]\n",
    "    \n",
    "    class_prob_distro = np.exp(classifier.feature_log_prob_[class_index])\n",
    "    alt_class_prob_distro = np.exp(classifier.feature_log_prob_[1 - class_index])\n",
    "    \n",
    "    odds_ratios = class_prob_distro / alt_class_prob_distro\n",
    "    odds_with_fns = sorted(zip(odds_ratios, feature_names), reverse = True)\n",
    "    \n",
    "    return odds_with_fns[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Look at the top thirty informative words for our reviewed and random poems. \n",
    "\n",
    "What kinds of patterns do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14.861096357476907, 'yews'),\n",
       " (14.39668709630576, 'braids'),\n",
       " (13.932277835134602, 'unlighted'),\n",
       " (13.003459312792291, 'persephone'),\n",
       " (12.074640790449976, 'blurring'),\n",
       " (11.145822268107672, 'unbreathed'),\n",
       " (11.145822268107672, 'shambles'),\n",
       " (11.145822268107672, 'palimpsest'),\n",
       " (11.145822268107672, 'easeful'),\n",
       " (10.217003745765371, 'whetting'),\n",
       " (10.217003745765371, 'unrolling'),\n",
       " (10.217003745765371, 'piazza'),\n",
       " (10.217003745765371, 'overwrought'),\n",
       " (10.217003745765371, 'mouthpiece'),\n",
       " (10.217003745765371, 'exhalation'),\n",
       " (10.217003745765371, 'bigelow'),\n",
       " (9.288185223423072, 'wherefrom'),\n",
       " (9.288185223423058, 'unshamed'),\n",
       " (9.288185223423058, 'unrestful'),\n",
       " (9.288185223423058, 'uncut'),\n",
       " (9.288185223423058, 'unbearable'),\n",
       " (9.288185223423058, 'shrewish'),\n",
       " (9.288185223423058, 'sacristan'),\n",
       " (9.288185223423058, 'nighest'),\n",
       " (9.288185223423058, 'maenads'),\n",
       " (9.288185223423058, 'foliaged'),\n",
       " (9.288185223423058, 'belfries'),\n",
       " (9.288185223423058, 'austerely'),\n",
       " (8.823775962251908, 'wilding'),\n",
       " (8.823775962251908, 'tugged')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solutions\n",
    "most_informative_features('review', top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13.996275577296228, 'minnie'),\n",
       " (12.919638994427288, 'instructions'),\n",
       " (12.919638994427288, 'acrostic'),\n",
       " (11.843002411558354, 'undertook'),\n",
       " (11.843002411558354, 'ke'),\n",
       " (11.843002411558354, 'indulging'),\n",
       " (11.843002411558354, 'frien'),\n",
       " (11.843002411558354, 'debase'),\n",
       " (11.843002411558354, 'alcohol'),\n",
       " (10.766365828689404, 'wrang'),\n",
       " (10.766365828689404, 'mell'),\n",
       " (10.766365828689404, 'investigation'),\n",
       " (10.766365828689404, 'fou'),\n",
       " (10.766365828689404, 'arranging'),\n",
       " (10.766365828689404, 'alane'),\n",
       " (9.689729245820475, 'weans'),\n",
       " (9.689729245820475, 'virus'),\n",
       " (9.689729245820475, 'velvety'),\n",
       " (9.689729245820475, 'val'),\n",
       " (9.689729245820475, 'propelled'),\n",
       " (9.689729245820475, 'legislative'),\n",
       " (9.689729245820475, 'ib'),\n",
       " (9.689729245820475, 'fulton'),\n",
       " (9.689729245820475, 'augmented'),\n",
       " (9.68972924582046, 'digression'),\n",
       " (9.151410954386009, 'insure'),\n",
       " (9.151410954386009, 'ag'),\n",
       " (8.613092662951532, 'extolled'),\n",
       " (8.613092662951532, 'bj'),\n",
       " (8.61309266295153, 'waur')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_informative_features('random', top_n=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
