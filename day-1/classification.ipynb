{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Supervised Machine Learning\n",
    "\n",
    "The goal of text classification is to categorize texts into any number of predefined categories. This method is most similar to traditional content analysis, or text coding, in that it does the same thing as a team of trained coders: place texts into categories. \n",
    "\n",
    "### Learning Goals\n",
    "* Get comfortable with the basic vocabulary of text classification\n",
    "* Understand the intuition behind supervised machine learning\n",
    "* Learn how to implement a few key supervised machine learning algorithms\n",
    "* Understand how to test for accuracy\n",
    "* Use scikit-learn to identify important features for each category\n",
    "* Gain the foundational knowledge for continued learning\n",
    "\n",
    "### Outline\n",
    "\n",
    "0. What text classification looks like\n",
    "1. The basics\n",
    "2. Reading in and pre-processing data\n",
    "3. Training and test sets\n",
    "4. Supervised Machine Learning Classification\n",
    "5. Prediction\n",
    "6. Cross Validation\n",
    "7. Identifying Features\n",
    "\n",
    "### Key Terms\n",
    "\n",
    "* *supervised machine learning* :\n",
    "    * using machine learning to infer documents' classifications from labeled training data\n",
    "* *model training* :\n",
    "    * using a machine learning algorithm to train a classifier to predict categories on unseen sets\n",
    "* *features*:\n",
    "    * way of representing the object that will be classified. For images, features are often pixels. For text, features are usually word counts or weighted word counts, but they can also be things like a word's part of speech, proportion of capitals, or specific words that are used.\n",
    "* *vectorization*:\n",
    "    * converting natural language documents into numbers that can be fed into a classifier. Usually this means converting a corpus into a Document-Term Matrix, containing raw counts or weighted proportions (like TF-IDF).\n",
    "* *train-test split*:\n",
    "    * dividing labeled data into a training set and a test set. Often done once in supervised machine learning model training, but can be done several times independently as in cross-validation\n",
    "* *training set*:\n",
    "    * a selection of labeled data that is used to train the machine learning algorithm\n",
    "* *test set*:\n",
    "    * a selection of labeled data that is used to test the accuracy of the machine learning algorithm\n",
    "* *unseen set*:\n",
    "    * a selection of *unlabeled* data - the machine learning algorithm predicts the label for these data. Also called the *holdout set*\n",
    "* *accuracy*:\n",
    "    * the proportion of texts an algorithm correctly classifies\n",
    "* *cross-validation*:\n",
    "    * a way to assess the performance of an algorithm on an unseen data set. Essentially this repeats a train-test split several times and averages the result of these independent slices, giving a superior estimation of model accuracy compared to a single train-test split\n",
    "    \n",
    "### Additional Resources:\n",
    "\n",
    "- [Documentation](http://scikit-learn.org/stable/supervised_learning.html) for supervised machine learning using scikit-learn\n",
    "- [Identifying what types of blog posts are censored in China](http://gking.harvard.edu/publications/how-censorship-china-allows-government-criticism-silences-collective-expression), using supervised machine learning, by Gary King, Jennifer Pan, and Margaret E Roberts\n",
    "- [Literary Pattern Recognition](https://lucian.uchicago.edu/blogs/literarynetworks/files/2015/12/LONG_SO_CI.pdf), by Hoyt Long, Richard So\n",
    "- [How Quickly Do Literary Standards Change?](https://tedunderwood.com/2015/05/18/how-quickly-do-literary-standards-change/), by Ted Underwood, Jordan Sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What text classification looks like<a id='example'></a>\n",
    "\n",
    "Imagine that you work at [YouTube](https://www.youtube.com/) (if you haven't heard of it, YouTube is a video-sharing website). Your job is to remove comments on videos that are spam (unsolicited and inappropriate comments). You look through each video and read the comments yourself, deciding which are spam and which are not spam. Perhaps you see comments like those below. Which would you consider to be spam and which not spam?\n",
    "\n",
    "- _Hey @dancer317, love ur videos so much! Thanks for all the tips on dancing!_\n",
    "- _OUR  LASER PRINTER/FAX/COPIER TONER CARTRIDGE PRICES NOW AS LOW AS 39 DOLLARS. SPECIALS WEEKLY ON ALL LASER PRINTER SUPPLIES. WE CARRY MOST ALL LASER PRINTER CARTRIDGES, FAX SUPPLIES AND COPIER TONERS AT WAREHOUSE PRICES_\n",
    "- _I'm not sold on your first point about crossing national boundaries, but I see what you mean about non-economic alternatives._\n",
    "- _Some of the most beautiful women in the world bare it all for you. Denise Richards, Britney  Spears, Jessica Simpson, and many more. CLICK HERE FOR NUDE CELEBS_\n",
    "\n",
    "How did you decide which were spam and which weren't? Maybe one thing you noted was the high number of words in all capitals. The topics can also give you a clue, as the spam-like comments talk about selling things and nudity, which are often found in spam comments.\n",
    "\n",
    "However you decided, we can think about the task you were doing like this:\n",
    "\n",
    "<img src='../assets/human-classification.jpg' />\n",
    "\n",
    "You took a comment written in English, and you classified it into one of two classes: spam or not spam. This is text classification, performed by a human. Wouldn't it be nice to have a computer do this for you? That would look like this: \n",
    "\n",
    "<img src='../assets/computer-classification.jpg' />\n",
    "\n",
    "How are we going to do this? We could count the number of times each YouTube comment mentions nudity or tries to sell something, and we could measure the proportion of capital letters. Using this approach, we would get two numbers for each comment, one for each of these _features_. We could also use your human judgements in a third column telling us whether that comment is spam or not.\n",
    "\n",
    "| Comment                                                 | Selling or nudity | Proportion capital letters | Is it spam? |\n",
    "|---------------------------------------------------------|-------------------|----------------------------|-------------|\n",
    "| Hey @dancer317, love ur videos so much! Thanks for ...  | 0                 | 0.1                        | No          |\n",
    "| OUR LASER PRINTER/FAX/COPIER TONER CARTRIDGE PRICES ... | 4                 | 1.0                        | Yes         |\n",
    "| I'm not sold on your first point ...                    | 1                 | 0.05                       | No          |\n",
    "|  Some of the most beautiful women in the world ...      | 3                 | 0.15                       | Yes         |\n",
    "\n",
    "We can treat these two numbers as geometric coordinates and plot them, with spam comments in red and non-spam comments in green, like so:\n",
    "\n",
    "<img src='../assets/classification-no-line.jpg' />\n",
    "\n",
    "<img src='../assets/classification-with-line.jpg' />\n",
    "\n",
    "\n",
    "## The basics<a id='basics'></a>\n",
    "\n",
    "Text classification requires labeled text, or text that is already categorized into predefined categories. In some cases, this is built into the data; in others, the labels are assigned by hand. Once we have a good number of labeled texts, usually between 200 and 500, we can use supervised machine learning algorithms to train a computer to recognize the categories and place the remaining, un-coded texts into a category. This method has two benefits: (1) It allows us to scale our coding up almost indefinitely, and (2) it identifies what *features* (in our case, words) are most defining of each category. This can help us learn more about the content of our categories.\n",
    "\n",
    "Text classification involves two primary tasks:\n",
    "- **Turning natural language into numbers.** (This is called _vectorization_.)\n",
    "- **Training a classifier to use those numbers and distinguish between the classes.**\n",
    "\n",
    "This is distinct from inductive natural language processing methods--such as topic modeling, which discover the categories making up texts rather than defining them from the outset. If you're testing hypotheses about buckets or categories of texts, you'll usually use classification; if you're exploring in the dark, you'll use a more exploratory method. Text categories to classify can also include genre, language, author, or [affective states][1].\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Affect_(psychology)\n",
    "\n",
    "Many applied natural language processing problems can be tackled as text classification:\n",
    "\n",
    "- [Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)\n",
    "- Genre classification\n",
    "- Language identification\n",
    "- Authorship attribution\n",
    "- Is this document relevant to this legal case?\n",
    "- Is the patient in need of urgent care?\n",
    "\n",
    "\n",
    "### 0. Reading in and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA <a id='eda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = '../../classification-intro-bacon-fa18/data'\n",
    "fname = os.path.join(DATA_DIR, 'tweets.csv')\n",
    "df = pd.read_csv(fname)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which airlines are tweeted about and how many of each in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['airline'], order=df['airline'].value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- How many tweets are in the dataset?\n",
    "- How many tweets are positive, neutral and negative?\n",
    "- What **proportion** of tweets are positive, neutral and negative?\n",
    "- Visualize these last two questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra challenge\n",
    "\n",
    "- When did the tweets come from?\n",
    "- Who gets more retweets: positive, negative or neutral tweets?\n",
    "- What are the reasons why people tweet negatively? Show distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess  <a id='preprocess'></a>\n",
    "\n",
    "### Regular expressions\n",
    "\n",
    "Regular expressions are like advanced find-and-replace. They allow us to specify complicated patterns in text data and find all the matches. They are very useful in text processing. You can learn more about them [here](https://github.com/geoffbacon/regular-expressions-in-python).\n",
    "\n",
    "We can use regular expressions to find hashtags and user mentions in a tweet. We first write the pattern we're looking for as a (raw) string, using regular expression's special syntax. The `twitter_handle_pattern` says \"find me a @ sign immediately followed by one or more upper or lower case letters, digits or underscore\". The `hashtag_pattern` is a little more complicated; it says \"find me exactly one ＃ or #, immediately followed by one or more upper or lower case letters, digits or underscore, but only if it's at the beginning of a line or immediately after a whitespace character\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "twitter_handle_pattern = r'@(\\w+)'\n",
    "hashtag_pattern = r'(?:^|\\s)[＃#]{1}(\\w+)'\n",
    "url_pattern = r'https?:\\/\\/.*.com'\n",
    "example_tweet = \"lol @justinbeiber and @BillGates are like soo #yesterday #amiright saw it on https://twitter.com #yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.findall(twitter_handle_pattern, example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.findall(hashtag_pattern, example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.findall(url_pattern, example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has great in-built support for operating with regular expressions on columns. We can `extract` all user mentions from a column of text like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'].str.extract(twitter_handle_pattern).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find all the hashtags like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'].str.extract(hashtag_pattern).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Often in preprocessing text data, we don't care about the exact hashtag/user/URL that someone used (although sometimes we do!). Your job is to replace all the hashtags with `'HASHTAG'`, the user mentions with `'USER'` and URLs with `'URL'`. To do this, you'll use the `replace` string method of the `text` column. The result of this will be a series, which you should add to `df` as a column called `clean_text`. **See the docs [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.replace.html) for more information on the method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Logistic regression with binary class\n",
    "\n",
    "To understand the theoretical gist of our classification task, let's first focus on a binary 'positive vs negative' classifier. We are going to do so by restricting the analysis to the non-neutral tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bin=df[df['airline_sentiment']!='neutral']\n",
    "len(df_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words and DTM\n",
    "\n",
    "First, we need to turn the text into numbers for our classifier. We're going to use a \"bag of words\" as our features. A bag of words is just like a frequency count of all the words that appear in a tweet. It's called a bag because we ignore the order of the words; we just care about what words are in the tweet. To do this, we can use `scikit-learn`'s `CountVectorizer` to build up the document-term matrix (see notebook from day 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(max_features=5000, binary=True)\n",
    "X = countvectorizer.fit_transform(df_bin['clean_text'])\n",
    "features = X.toarray()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = df_bin['airline_sentiment'].values\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test datasets\n",
    "\n",
    "We don't want to train our classifier on the same dataset that we test it on, so let's split it into training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, response, test_size=0.2)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a logistic regression model\n",
    "\n",
    "OK, so now that we've turned our data into numbers, we're ready to feed it into a classifier. More specifically, we are going to fit a logistic regression model where the probability of being positive ($y=1$) is described by a sigmoid function of the form:\n",
    "$f(X)=P(y=1|X)=\\frac{exp(-X'\\theta)}{1+exp(-X'\\theta)}$. Once $\\theta$ - a vector of word _weights_ or _loadings_ - is estimated we can get predict outcomes $\\hat{f}$ conditional on observed word count $X$. If $\\hat{f}>0.5$ then the observation is classified as positive. This is a _linear classifier_ as the decision boundary is defined by $\\frac{exp(-X'\\theta)}{1+exp(-X'\\theta)}=0.5$, which after reaaranging and taking logs appears equivalent to $-X'\\theta=0$ - a linear function of the features $X$.\n",
    "\n",
    "To those interested in the technicalities, the model is estimated through penalized Maximum Likelihood with cross-validation. (It's always good to know and understand at a high-level what your code is actually doing...)  \n",
    "\n",
    "We're not going to concentrate too much on the code below, but here's the big picture. In the `fit_model` function defined below, we're going to use the logitistic regression classifier described abover to take in the numerical representation of the tweets and spit out whether it's positive or negative. Then we'll use `test_model` to test the model's performance against our test data and print out some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_logistic_regression(X, y):\n",
    "    model = LogisticRegressionCV(Cs=5, penalty='l1', cv=3, solver='liblinear', refit=True)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def conmat(model, X, y):\n",
    "    \"\"\"Wrapper for sklearn's confusion matrix.\"\"\"\n",
    "    labels = model.classes_\n",
    "    y_pred = model.predict(X)\n",
    "    c = confusion_matrix(y, y_pred)\n",
    "    sns.heatmap(c, annot=True, fmt='d', \n",
    "                xticklabels=labels, \n",
    "                yticklabels=labels, \n",
    "                cmap=\"YlGnBu\", cbar=False)\n",
    "    plt.ylabel('Ground truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    \n",
    "def test_model(model, X, y):\n",
    "    conmat(model, X_test, y_test)\n",
    "    print('Accuracy: ', model.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "lr = fit_logistic_regression(X_train, y_train)\n",
    "\n",
    "test_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = fit_logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "\n",
    "Fit a _multinomial_ logit model to classify tweets between positive, negative AND neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2\n",
    "\n",
    "Use the `RandomForestClassifier` imported above to construc a `fit_random_forest` function and train a random forest classifier on the training set. Test the model on the test set. Which performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More validation\n",
    "\n",
    "We are going to use the `test_tweet` function below to test your classifier's performance on our own tweets. We can do it using both LR or RF classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    tweets = [re.sub(hashtag_pattern, 'HASHTAG', t) for t in tweets]\n",
    "    tweets = [re.sub(twitter_handle_pattern, 'USER', t) for t in tweets]\n",
    "    return [re.sub(url_pattern, 'URL', t) for t in tweets]\n",
    "\n",
    "def test_tweets(tweets, model):\n",
    "    tweets = clean_tweets(tweets)\n",
    "    features = countvectorizer.transform(tweets)\n",
    "    predictions = model.predict(features)\n",
    "    return list(zip(tweets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tweets = [example_tweet,\n",
    "            'omg I am never flying on United again',\n",
    "            'I love @VirginAmerica so much #friendlystaff',\n",
    "            'food on Air France is great!']\n",
    "\n",
    "test_tweets(my_tweets, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret <a id='interpret'></a>\n",
    "\n",
    "Now we can interpret the classifier by the features that it found important. Let's do it for our preferred logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important = pd.DataFrame(lr.coef_).T\n",
    "important.columns = lr.classes_\n",
    "important['word'] = countvectorizer.get_feature_names()\n",
    "important.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important.sort_values(by='negative', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important.sort_values(by='positive', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
