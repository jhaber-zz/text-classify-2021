{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Supervised Machine Learning\n",
    "\n",
    "The goal of text classification is to categorize texts into any number of predefined categories. This method is most similar to traditional content analysis, or text coding, in that it does the same thing as a team of trained coders: place texts into categories. Unlike regression, the outcome in text classification must be categorical. \n",
    "\n",
    "Using supervised machine learning, we give an algorithm a dataset of training examples that say \"here are specific features, and this is the category it belongs to\". The algorithm trains a model to recognize important features and determine the category of an object (for us, a document); this model can then be used to predict the class of a new object given its known features. \n",
    "\n",
    "To train and evaluate our models, we will use [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html), which provides a full machine learning pipeline and many convenient functions in Python.\n",
    "\n",
    "We will apply supervised machine learning to a corpus distributed by Ted Underwood and Jordan Sellers in support of their own [literary historical study](https://tedunderwood.com/2015/05/18/how-quickly-do-literary-standards-change/) on nineteenth- and early-twentieth century volumes of poetry. Some poems were reviewed in prestigious magazines, while others weren't--being reviewed is our outcome variable. Even a negative review indicates valuable, critical engagement, so predicting whether a poem is reviewed will tell us something about the vocabulary of literary prestige.\n",
    "\n",
    "## Learning Goals\n",
    "* Get comfortable with the basic vocabulary of text classification\n",
    "* Understand the intuition behind supervised machine learning\n",
    "* Learn how to implement logistic regression and its basic mechanics\n",
    "* Learn how to test for accuracy\n",
    "* Use scikit-learn to identify important features for each category\n",
    "* Gain foundational knowledge for continued learning\n",
    "\n",
    "## Outline\n",
    "\n",
    "* [Introduction](#intro)\n",
    "    * [Text classification in action](#example)\n",
    "    * [Text classification basics](#basics)\n",
    "* [Data preparation](#prepare)\n",
    "    * [Import modules](#import)\n",
    "    * [Read and preprocess data](#preprocess)\n",
    "    * [Divide data into training and test sets](#split)\n",
    "    * [Vectorize texts](#vectorize)\n",
    "* [Classification with supervised machine learning](#supervised)\n",
    "    * [Train logistic classifier model](#model)\n",
    "    * [Prediction on new data](#prediction)\n",
    "    * [Identify features](#features)\n",
    "\n",
    "## Key Terms\n",
    "\n",
    "* *supervised machine learning* :\n",
    "    * Building a model to infer objects' classifications from labeled training data based on input variables, known as features. Learning a function that maps features to outputs.\n",
    "* *model training* :\n",
    "    * Using a machine learning algorithm to train a classifier to predict categories on unseen sets\n",
    "* *features*:\n",
    "    * Way of representing the object that will be classified. For images, features are often pixels. For text, features are usually word counts or weighted word counts, but they can also be things like a word's part of speech, proportion of capitals, or specific words that are used.\n",
    "* *unsupervised machine learning*:\n",
    "    * Learning patterns or structure across a set of variables through their statistical associations. Uses include discovering latent clusters or dimensions, reducing dimensionality, outlier detection, probability density estimation.\n",
    "* *loss function*:\n",
    "    * Machine learning models seek to minimize this function, which measures model effectiveness at estimating the relationship between an input (features) and output variable. This is typically expressed as a difference between the predicted value and the actual value. \n",
    "* *text vectorization*:\n",
    "    * Converting natural language documents into numbers that can be fed into a classifier. Usually this means converting a corpus into a document-term matrix.\n",
    "* *document-term matrix (DTM)*:\n",
    "    * A common text vectorization method: essentially a big table where the rows are articles, the columns are words, and each cell indicates the number of a times a given word appears in a given article. The cells can be either raw counts or weighted proportions, like with term frequency inverse document frequency (TF-IDF) weighting--which gives a word greater weight both when it is more frequent in a text AND when it is rare across the corpus. \n",
    "* *train-test split*:\n",
    "    * Dividing labeled data into a training set and a test set. Often done once in supervised machine learning model training, but can be done several times independently as in cross-validation (we'll see this tomorrow)\n",
    "* *training set*:\n",
    "    * A selection of labeled data that is used to train the machine learning algorithm\n",
    "* *test set*:\n",
    "    * A selection of labeled data that is used to test the accuracy of the machine learning algorithm\n",
    "* *unseen set*:\n",
    "    * A selection of *unlabeled* data - the machine learning algorithm predicts the label for these data. Also called the *holdout set*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction<a id='intro'></a>\n",
    "\n",
    "## Text classification in action<a id='example'></a>\n",
    "\n",
    "Imagine that you work at [YouTube](https://www.youtube.com/) (if you haven't heard of it, YouTube is a video-sharing website). Your job is to remove comments on videos that are spam (unsolicited and inappropriate comments). You look through each video and read the comments yourself, deciding which are spam and which are not spam. Perhaps you see comments like those below. Which would you consider to be spam and which not spam?\n",
    "\n",
    "- _Hey @dancer317, love ur videos so much! Thanks for all the tips on dancing!_\n",
    "- _OUR  LASER PRINTER/FAX/COPIER TONER CARTRIDGE PRICES NOW AS LOW AS 39 DOLLARS. SPECIALS WEEKLY ON ALL LASER PRINTER SUPPLIES. WE CARRY MOST ALL LASER PRINTER CARTRIDGES, FAX SUPPLIES AND COPIER TONERS AT WAREHOUSE PRICES_\n",
    "- _I'm not sold on your first point about crossing national boundaries, but I see what you mean about non-economic alternatives._\n",
    "- _Some of the most beautiful women in the world bare it all for you. Denise Richards, Britney  Spears, Jessica Simpson, and many more. CLICK HERE FOR NUDE CELEBS_\n",
    "\n",
    "How did you decide which were spam and which weren't? Maybe one thing you noted was the high number of words in all capitals. The topics can also give you a clue, as the spam-like comments talk about selling things and nudity, which are often found in spam comments.\n",
    "\n",
    "However you decided, we can think about the task you were doing like this:\n",
    "\n",
    "<img src='../assets/human-classification.jpg' />\n",
    "\n",
    "You took a comment written in English, and you classified it into one of two classes: spam or not spam. This is text classification, performed by a human. Wouldn't it be nice to have a computer do this for you? That would look like this: \n",
    "\n",
    "<img src='../assets/computer-classification.jpg' />\n",
    "\n",
    "How are we going to do this? We could count the number of times each YouTube comment mentions nudity or tries to sell something, and we could measure the proportion of capital letters. Using this approach, we would get two numbers for each comment, one for each of these _features_. We could also use your human judgements in a third column telling us whether that comment is spam or not.\n",
    "\n",
    "| Comment                                                 | Selling or nudity | Proportion capital letters | Is it spam? |\n",
    "|---------------------------------------------------------|-------------------|----------------------------|-------------|\n",
    "| Hey @dancer317, love ur videos so much! Thanks for ...  | 0                 | 0.1                        | No          |\n",
    "| OUR LASER PRINTER/FAX/COPIER TONER CARTRIDGE PRICES ... | 4                 | 1.0                        | Yes         |\n",
    "| I'm not sold on your first point ...                    | 1                 | 0.05                       | No          |\n",
    "|  Some of the most beautiful women in the world ...      | 3                 | 0.15                       | Yes         |\n",
    "\n",
    "We can treat these two numbers as geometric coordinates and plot them, with spam comments in red and non-spam comments in green, like so:\n",
    "\n",
    "<img src='../assets/classification-no-line.jpg' />\n",
    "\n",
    "<img src='../assets/classification-with-line.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification basics<a id='basics'></a>\n",
    "\n",
    "Text classification requires labeled text, or text that is already categorized into predefined categories. In some cases, this is built into the data; in others, the labels are assigned by hand. Once we have a good number of labeled texts, usually between 200 and 500, we can use supervised machine learning algorithms to train a model to recognize the categories and place the remaining, un-coded texts into a category. This method has two benefits: (1) It allows us to scale our coding up almost indefinitely, and (2) it identifies what *features* (in our case, words) are most defining of each category. This can help us learn more about the content of our categories.\n",
    "\n",
    "Text classification involves two primary tasks:\n",
    "- **Turning natural language into numbers.** (This is called _vectorization_.)\n",
    "- **Training a classifier to use those numbers and distinguish between the classes.**\n",
    "\n",
    "This is distinct from inductive natural language processing methods--such as topic modeling, which discover the categories making up texts rather than defining them from the outset; clustering texts based on language patterns; or dimensionality reduction. If you're testing hypotheses about buckets or categories of texts, you'll usually use classification; if you're exploring in the dark, you'll use unsupervised machine learning for exploration. Text categories to classify can also include genre, language, author, or [affective states][1].\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Affect_(psychology)\n",
    "\n",
    "Many applied natural language processing problems can be tackled as text classification:\n",
    "\n",
    "- [Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)\n",
    "- Genre classification\n",
    "- Language identification\n",
    "- Authorship attribution\n",
    "- Is this document relevant to this legal case?\n",
    "- Is the patient in need of urgent care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation<a id='preparation'></a>\n",
    "\n",
    "## Import modules<a id='import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#scikit-learn is a huge library. We import what we need.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split #shortcut for dividing into train and test data\n",
    "from sklearn.metrics import confusion_matrix #shows confusion matrix--false/true positives/negatives\n",
    "from sklearn.metrics import accuracy_score #to asses the accuracy of the algorithm\n",
    "from sklearn.model_selection import cross_val_score #to compute cross validation for assessment purposes\n",
    "from sklearn.svm import LinearSVC #Linear Support Vector Classifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV #Logistic regression classifier w/ and w/o cross-validation\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess data<a id='preprocess'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read our texts and turn them into lists\n",
    "import os\n",
    "review_path = 'poems/reviewed/'\n",
    "random_path = 'poems/random/'\n",
    "review_files = os.listdir(review_path)\n",
    "random_files = os.listdir(random_path)\n",
    "\n",
    "review_texts = [open(review_path+file_name, encoding='utf-8').read() for file_name in review_files]\n",
    "random_texts = [open(random_path+file_name, encoding='utf-8').read() for file_name in random_files]\n",
    "\n",
    "review_texts[0] #notice the strange output here. These poems are saved in a bag of words format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transform and concat these lists into a Pandas dataframe\n",
    "df1 = pandas.DataFrame(review_texts, columns = ['body'])\n",
    "df1['label'] = \"review\"\n",
    "df2 = pandas.DataFrame(random_texts, columns = ['body'])\n",
    "df2['label'] = \"random\"\n",
    "df = pandas.concat([df1,df2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Output some summary statistics for this dataframe. \n",
    "- How many poems have the review label, and how many bear the random label? \n",
    "- What is the total number of words in each category? \n",
    "- What is the average number of words per poem in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into training and test sets<a id='split'></a>\n",
    "\n",
    "To avoid overfitting, let's train our classifier on a different dataset from what we test it on. To accomplish this, we'll split it into training and test sets: we'll train on the first 500 poems, and test the accuracy on the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize our rows\n",
    "df = df.sample(720, random_state=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two new dataframes\n",
    "df_train = df[:500]\n",
    "df_test = df[500:]\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize texts<a id='vectorize'></a>\n",
    "\n",
    "Next, we turn the text into numbers for our classifier. We will use a \"bag of words\" approach to create our features: frequency counts of all the words that appear in a text. The \"bag\" name is because we ignore the order of the words; we just care about what words are in the text, as if we threw all the words into a bag and shook them up. To do this, we use `scikit-learn`'s `CountVectorizer` to build a document-term matrix (DTM). You can think of a DTM as a big table where the rows are articles, the columns are words, and each cell indicates the number of a times a given word appears in a given article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the 'body' column into a document term matrix\n",
    "countvec = CountVectorizer(stop_words = 'english', min_df = 1, binary=True)\n",
    "\n",
    "training_dtm_tf = countvec.fit_transform(df_train.body)\n",
    "test_dtm_tf = countvec.transform(df_test.body)\n",
    "\n",
    "#create an array for labels\n",
    "training_labels = df_train.label\n",
    "test_labels = df_test.label\n",
    "test_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with supervised machine learning<a id='supervised'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic classifier model<a id='model'></a>\n",
    "\n",
    "Now that we've turned our data into numbers, we're ready to feed it into a classifier. Let's start with one of the more common algorithms for classification, called [logistic regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression). It's good to know what our code is doing, so let's go over how this works at a high level.\n",
    "\n",
    "Logistic models fit where the probability of being positive ($y=1$) is described by a sigmoid function of the form:\n",
    "$f(X)=P(y=1|X)=\\frac{exp(-X'\\theta)}{1+exp(-X'\\theta)}$. Once $\\theta$ - a vector of word _weights_ or _loadings_ - is estimated we can predict outcomes $\\hat{f}$ conditional on observed word count $X$. If $\\hat{f}>0.5$ then the observation is classified as positive. This is a _linear classifier_ as the decision boundary is defined by $\\frac{exp(-X'\\theta)}{1+exp(-X'\\theta)}=0.5$, which after rearranging and taking logs appears equivalent to $-X'\\theta=0$ - a linear function of the features $X$. \n",
    "\n",
    "Logistic regression is estimated through penalized Maximum Likelihood. This is a form of a _loss (cost) function_:\n",
    "\n",
    "\"A cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y. This is typically expressed as a difference or distance between the predicted value and the actual value. ... The objective of a ML model, therefore, is to find parameters, weights or a structure that minimises the cost function.\" <br/>-Conor McDonald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a container for our chosen algorithm, in this case logistic regression\n",
    "#one object contains all the functions for fitting data, making predictions, and storing parameters\n",
    "logit = LogisticRegression()\n",
    "\n",
    "#fit a model on our training set\n",
    "logit.fit(training_dtm_tf, training_labels)\n",
    "\n",
    "#predict the labels on the test set using the trained model\n",
    "predictions_logit = logit.predict(test_dtm_tf) \n",
    "predictions_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the built-in `accuracy_score` function to calculate the accuracy of our classifier. Basically, this number represents the proportion of texts an algorithm correctly classifies (we will go over this more tomorrow). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predictions_logit, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see if tf-idf weighting improves the accuracy\n",
    "tfidfvec = TfidfVectorizer(stop_words = 'english', min_df = 1, binary=True)\n",
    "training_dtm_tfidf = tfidfvec.fit_transform(df_train.body)\n",
    "test_dtm_tfidf = tfidfvec.transform(df_test.body)\n",
    "\n",
    "logit.fit(training_dtm_tfidf, training_labels)\n",
    "predictions_tfidf = logit.predict(test_dtm_tfidf) \n",
    "accuracy_score(predictions_tfidf, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "A common practice in machine learning is to quickly try a bunch of algorithms, see which one works the best, and optimize it. In this spirit...\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Apply these two additional algorithms without bothering to learn how they work: \n",
    "- Linear Support Vector Classification (`LinearSVC()`) and \n",
    "- Multinomial Naive Bayes (`MultinomialNB()`)\n",
    "    \n",
    "To avoid a long delay, with `LinearSVC()` set `max_iter` to 20. \n",
    "\n",
    "Train each of these on the training set and evaluate accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**\n",
    "\n",
    "Try to improve the accuracy of either of these models by changing a few model parameters or the vectorizer function. (Decreases in accuracy are also informative.) This is basically a brute-force method of model optimization, which we'll learn more about tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on new data<a id='prediction'></a>\n",
    "\n",
    "Often what we want to do next is predict the label for unlabeled texts. Let's predict the label for two poems where we do not know the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickinson_canonic = \"\"\"Because I could not stop for Death – \n",
    "He kindly stopped for me –  \n",
    "The Carriage held but just Ourselves –  \n",
    "And Immortality.\n",
    "\n",
    "We slowly drove – He knew no haste\n",
    "And I had put away\n",
    "My labor and my leisure too,\n",
    "For His Civility – \n",
    "\n",
    "We passed the School, where Children strove\n",
    "At Recess – in the Ring –  \n",
    "We passed the Fields of Gazing Grain –  \n",
    "We passed the Setting Sun – \n",
    "\n",
    "Or rather – He passed us – \n",
    "The Dews drew quivering and chill – \n",
    "For only Gossamer, my Gown – \n",
    "My Tippet – only Tulle – \n",
    "\n",
    "We paused before a House that seemed\n",
    "A Swelling of the Ground – \n",
    "The Roof was scarcely visible – \n",
    "The Cornice – in the Ground – \n",
    "\n",
    "Since then – ‘tis Centuries – and yet\n",
    "Feels shorter than the Day\n",
    "I first surmised the Horses’ Heads \n",
    "Were toward Eternity – \"\"\"\n",
    "\n",
    "\n",
    "anthem_patriotic = \"\"\"O! say can you see, by the dawn's early light,\n",
    "What so proudly we hailed at the twilight's last gleaming,\n",
    "Whose broad stripes and bright stars through the perilous fight,\n",
    "O'er the ramparts we watched, were so gallantly streaming?\n",
    "And the rockets' red glare, the bombs bursting in air,\n",
    "Gave proof through the night that our flag was still there;\n",
    "O! say does that star-spangled banner yet wave\n",
    "O'er the land of the free and the home of the brave?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform these into DTMs with the same feature-columns as previously\n",
    "unknown_dtm = countvec.transform([dickinson_canonic,anthem_patriotic]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return binary classification\n",
    "logit.predict(unknown_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return probability of classification. \n",
    "# Bayes theorem assigns a probability of membership in either category.\n",
    "# Just how confident is our classifier of its predictions?\n",
    "\n",
    "logit.predict_proba(unknown_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's zip this together with the name of the poems to make sense of the output\n",
    "list(zip(['dickinson', 'anthem'], logit.predict(unknown_dtm), logit.predict_proba(unknown_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Import and process the 'canonic' (albeit unreviewed) volumes of poetry. Use the poetry classifier to predict whether they might have been reviewed.\n",
    "\n",
    "What do you think of the output? Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify features<a id='features'></a>\n",
    "\n",
    "We can use supervised machine learning to classify unseen documents using the above code. But we can also use it to learn more about the content of each category, by extracting the most defining features of this category. So even if we do not have unseen text, we can use this method to better understand given categories (for example, canonized and non-canonized text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand-waving the underlying statistics here...\n",
    "nb = MultinomialNB() # naive bayes works best for this math\n",
    "nb.fit(training_dtm_tf, training_labels) # fit model\n",
    "\n",
    "def most_informative_features(text_class, vectorizer = countvec, classifier = nb, top_n = 20):\n",
    "    \"\"\"Returns feature name and odds ratio for a given class\"\"\"\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    class_index = np.where(classifier.classes_==(text_class))[0][0]\n",
    "    \n",
    "    class_prob_distro = np.exp(classifier.feature_log_prob_[class_index])\n",
    "    alt_class_prob_distro = np.exp(classifier.feature_log_prob_[1 - class_index])\n",
    "    \n",
    "    odds_ratios = class_prob_distro / alt_class_prob_distro\n",
    "    odds_with_fns = sorted(zip(odds_ratios, feature_names), reverse = True)\n",
    "    \n",
    "    return odds_with_fns[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at most informative features for poems that were reviewed\n",
    "most_informative_features('review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_informative_features('random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Look at the top fifty informative words for each category. \n",
    "\n",
    "What kinds of patterns do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
